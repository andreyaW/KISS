{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is meant to help determine how to setup a Markov Chain transitin matrix to reflect a desired MTTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: create a function that defines the transition matrix for a two state markov chain that must meet a specified MTTF\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_mttf_markov_chain(mttf, time_step):\n",
    "  \"\"\"\n",
    "  Creates a 2-state Markov chain transition matrix that meets a specified MTTF.\n",
    "\n",
    "  The two states are assumed to be 'Operational' and 'Failed'.\n",
    "  The transition probabilities are defined as follows:\n",
    "  P(Operational -> Operational) = p\n",
    "  P(Operational -> Failed) = 1-p\n",
    "  P(Failed -> Failed) = 1 (assuming failure is an absorbing state)\n",
    "  P(Failed -> Operational) = 0 (assuming failure is an absorbing state)\n",
    "\n",
    "  The Mean Time To Failure (MTTF) is the expected time to reach the Failed state\n",
    "  from the Operational state. For this simple Markov chain, the MTTF is given by\n",
    "  MTTF = time_step / (1-p)\n",
    "  We can solve for p: p = 1 - (time_step / MTTF)\n",
    "\n",
    "  Args:\n",
    "  X\n",
    "  Returns:\n",
    "    A 2x2 numpy array representing the transition matrix.\n",
    "    Returns None if a valid transition matrix cannot be created (e.g., mttf <= time_step).\n",
    "  \"\"\"\n",
    "  if mttf <= time_step:\n",
    "    print(\"Error: MTTF must be greater than the time step.\")\n",
    "    return None\n",
    "\n",
    "  # Calculate the probability of staying in the operational state\n",
    "  p = 1 - (time_step / mttf)\n",
    "\n",
    "  # Define the transition matrix\n",
    "  # Rows represent current state (0: Operational, 1: Failed)\n",
    "  # Columns represent next state (0: Operational, 1: Failed)\n",
    "  transition_matrix = np.array([\n",
    "      [p, 1 - p],  # Transitions from Operational\n",
    "      [0, 1]       # Transitions from Failed (absorbing state)\n",
    "  ])\n",
    "\n",
    "  return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix:\n",
      "[[0.9 0.1]\n",
      " [0.  1. ]]\n",
      "\n",
      "Probability of failure in one step: 0.1000\n",
      "Expected MTTF based on calculated probability: 100.00\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "mttf_value = 100  # Desired MTTF\n",
    "step_duration = 10 # Time step\n",
    "\n",
    "transition_matrix = create_mttf_markov_chain(mttf_value, step_duration)\n",
    "\n",
    "if transition_matrix is not None:\n",
    "  print(\"Transition Matrix:\")\n",
    "  print(transition_matrix)\n",
    "\n",
    "  # Verify MTTF (approximately, due to discrete time steps)\n",
    "  # For a more accurate verification, you would simulate or use absorbing Markov chain analysis\n",
    "  # Let's do a simple check of the probability of failure in one step\n",
    "  prob_failure_in_one_step = transition_matrix[0, 1]\n",
    "  print(f\"\\nProbability of failure in one step: {prob_failure_in_one_step:.4f}\")\n",
    "  print(f\"Expected MTTF based on calculated probability: {step_duration / prob_failure_in_one_step:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transition Matrix for 3 operational states (Total 4 states):\n",
      "[[0.9 0.  0.  0.1]\n",
      " [0.  0.9 0.  0.1]\n",
      " [0.  0.  0.9 0.1]\n",
      " [0.  0.  0.  1. ]]\n",
      "\n",
      "Probability of failure from any operational state in one step: 0.1000\n",
      "Expected MTTF based on calculated probability: 100.00\n",
      "\n",
      "Simulating 100 Markov chains with 4 states:\n",
      "\n",
      "Average simulated failure time across completed chains (100 failures): 113.20\n"
     ]
    }
   ],
   "source": [
    "# prompt: recreate the mttf_markov_chain function to work for n possible states\n",
    "\n",
    "import numpy as np\n",
    "def create_mttf_markov_chain_n_states(mttf, time_step, num_operational_states):\n",
    "  \"\"\"\n",
    "  Creates an (n+1)-state Markov chain transition matrix that meets a specified MTTF.\n",
    "\n",
    "  The states are assumed to be 'Operational_0', 'Operational_1', ...,\n",
    "  'Operational_{n-1}' and 'Failed' (state n).\n",
    "  Assumes transitions are only from an Operational state to the Failed state.\n",
    "  All Operational states are assumed to have the same probability of transitioning\n",
    "  to the Failed state per time step to achieve the desired MTTF.\n",
    "  The Failed state is an absorbing state.\n",
    "\n",
    "  The Mean Time To Failure (MTTF) from any Operational state is the expected\n",
    "  time to reach the Failed state.\n",
    "  MTTF = time_step / P(transition to Failed from any operational state)\n",
    "\n",
    "  Args:\n",
    "    mttf: The desired Mean Time To Failure in the same time units as time_step.\n",
    "    time_step: The duration of each step in the Markov chain.\n",
    "    num_operational_states: The number of operational states (n). The total\n",
    "                            number of states will be n+1 (n operational + 1 failed).\n",
    "\n",
    "  Returns:\n",
    "    An (n+1)x(n+1) numpy array representing the transition matrix.\n",
    "    Returns None if a valid transition matrix cannot be created (e.g., mttf <= time_step).\n",
    "  \"\"\"\n",
    "  if mttf <= time_step:\n",
    "    print(\"Error: MTTF must be greater than the time step.\")\n",
    "    return None\n",
    "\n",
    "  if num_operational_states <= 0:\n",
    "    print(\"Error: Number of operational states must be positive.\")\n",
    "    return None\n",
    "\n",
    "  total_states = num_operational_states + 1 # Operational states + Failed state\n",
    "\n",
    "  # Calculate the probability of transitioning to the Failed state from any\n",
    "  # operational state. This probability is assumed to be the same for all\n",
    "  # operational states for this simplified model to meet the single MTTF requirement.\n",
    "  prob_to_failed = time_step / mttf\n",
    "\n",
    "  if prob_to_failed > 1:\n",
    "       print(f\"Error: Calculated probability to failed ({prob_to_failed:.4f}) is greater than 1. \"\n",
    "             \"Increase MTTF or decrease time_step.\")\n",
    "       return None\n",
    "\n",
    "  # The probability of staying in the operational state cluster (or transitioning\n",
    "  # between operational states) is 1 - prob_to_failed for each operational state.\n",
    "  # For this simplified model, we assume all remaining probability is for staying\n",
    "  # within the operational states (e.g., equally distributed among other operational\n",
    "  # states including the current one, or just staying in the current one if no\n",
    "  # transitions between operational states are modeled explicitly).\n",
    "  # We'll assume for this simple model that the remaining probability is distributed\n",
    "  # among the *other* operational states and potentially staying in the current one.\n",
    "  # A simple way to distribute this is equally among all operational states, including the current one.\n",
    "  # Let's simplify further: assume the remaining probability (1 - prob_to_failed)\n",
    "  # is distributed among the 'num_operational_states' operational states.\n",
    "  # A common pattern is to assume the system stays in the same operational state\n",
    "  # with probability (1 - prob_to_failed) and transitions to failed with prob_to_failed.\n",
    "  # Or, if states represent progressive degradation, the probability might be\n",
    "  # of moving to the *next* operational state.\n",
    "  # Let's implement the simple case: from any operational state, you either stay\n",
    "  # in that state or transition to failed. This implies no transitions *between*\n",
    "  # operational states. This still gives MTTF = time_step / prob_to_failed\n",
    "  # from any operational state as long as state 0 is the starting state.\n",
    "\n",
    "  # If states represent a sequence 0 -> 1 -> ... -> n-1 -> n (Failed),\n",
    "  # then from state i (i < n-1), prob to i+1 is p, prob to n (Failed) is q.\n",
    "  # From state n-1, prob to n (Failed) is r.\n",
    "  # This makes the MTTF calculation more complex.\n",
    "\n",
    "  # Let's stick to the interpretation closest to the original 2-state model:\n",
    "  # there's a set of operational states, and from *any* operational state, there's\n",
    "  # a probability 'q' of going to the single 'Failed' state, and probability '1-q'\n",
    "  # of staying within the set of operational states (e.g., staying in the same state).\n",
    "  # The MTTF from any operational state is time_step / q. So, q = time_step / mttf.\n",
    "\n",
    "  transition_matrix = np.zeros((total_states, total_states))\n",
    "\n",
    "  # Fill in transitions from operational states (0 to num_operational_states-1)\n",
    "  prob_stay_operational = 1 - prob_to_failed\n",
    "\n",
    "  for i in range(num_operational_states):\n",
    "    # Assume the probability of staying in the *set* of operational states\n",
    "    # is distributed among the operational states.\n",
    "    # For simplicity, let's assume the probability of staying in the *same*\n",
    "    # operational state is `prob_stay_operational`.\n",
    "    transition_matrix[i, i] = prob_stay_operational\n",
    "    # And the probability of transitioning to the Failed state is `prob_to_failed`.\n",
    "    transition_matrix[i, num_operational_states] = prob_to_failed\n",
    "\n",
    "\n",
    "  # The Failed state (index num_operational_states) is an absorbing state\n",
    "  transition_matrix[num_operational_states, num_operational_states] = 1.0\n",
    "\n",
    "  # Optional: If transitions between operational states are needed,\n",
    "  # the prob_stay_operational would be distributed differently.\n",
    "  # E.g., probability of moving to the next state (i+1) could be prob_stay_operational,\n",
    "  # and the diagonal would be 0 for operational states except the last one.\n",
    "  # This simplified model assumes no transitions between operational states explicitly.\n",
    "\n",
    "  return transition_matrix\n",
    "\n",
    "# Example usage for N states:\n",
    "mttf_value_n = 100  # Desired MTTF\n",
    "step_duration_n = 10 # Time step\n",
    "num_op_states = 3    # Number of operational states\n",
    "\n",
    "transition_matrix_n = create_mttf_markov_chain_n_states(mttf_value_n, step_duration_n, num_op_states)\n",
    "\n",
    "if transition_matrix_n is not None:\n",
    "  print(f\"\\nTransition Matrix for {num_op_states} operational states (Total {num_op_states+1} states):\")\n",
    "  print(transition_matrix_n)\n",
    "\n",
    "  # Verify MTTF (approximately)\n",
    "  # The probability of failure from any operational state in one step is the value\n",
    "  # in the last column (Failed state).\n",
    "  # For this matrix structure, it's the same for all operational states.\n",
    "  prob_failure_in_one_step_n = transition_matrix_n[0, num_op_states] # Or any operational state row\n",
    "  print(f\"\\nProbability of failure from any operational state in one step: {prob_failure_in_one_step_n:.4f}\")\n",
    "  # This should be equal to step_duration_n / mttf_value_n\n",
    "  print(f\"Expected MTTF based on calculated probability: {step_duration_n / prob_failure_in_one_step_n:.2f}\")\n",
    "\n",
    "# Simulate with N states:\n",
    "def simulate_markov_chains_n_states(transition_matrix, num_simulations, max_steps, starting_state=0):\n",
    "  \"\"\"\n",
    "  Simulates multiple Markov chains based on a given transition matrix.\n",
    "\n",
    "  Args:\n",
    "    transition_matrix: A numpy array representing the transition matrix.\n",
    "    num_simulations: The number of independent Markov chains to simulate.\n",
    "    max_steps: The maximum number of steps to simulate for each chain.\n",
    "    starting_state: The initial state for the simulations (default is state 0).\n",
    "\n",
    "  Returns:\n",
    "    A list of lists, where each inner list represents the sequence of states\n",
    "    for one simulation.\n",
    "  \"\"\"\n",
    "  num_states = transition_matrix.shape[0]\n",
    "  simulations = []\n",
    "  failed_state_index = num_states - 1 # Assuming the last state is the failed state\n",
    "\n",
    "  for _ in range(num_simulations):\n",
    "    current_state = starting_state\n",
    "    chain = [current_state]\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "      # If the current state is the absorbing state (Failed), stay there\n",
    "      if current_state == failed_state_index:\n",
    "        chain.append(current_state)\n",
    "        continue\n",
    "\n",
    "      # Determine the probabilities for the next state based on the current state\n",
    "      probabilities = transition_matrix[current_state, :]\n",
    "\n",
    "      # Sample the next state based on the probabilities\n",
    "      next_state = np.random.choice(num_states, p=probabilities)\n",
    "\n",
    "      chain.append(next_state)\n",
    "      current_state = next_state\n",
    "\n",
    "    simulations.append(chain)\n",
    "\n",
    "  return simulations\n",
    "\n",
    "if transition_matrix_n is not None:\n",
    "  num_simulations_n = 100\n",
    "  max_simulation_steps_n = 500 # Increase max steps as MTTF is higher\n",
    "\n",
    "  simulated_chains_n = simulate_markov_chains_n_states(transition_matrix_n, num_simulations_n, max_simulation_steps_n, starting_state=0) # Start in state 0\n",
    "\n",
    "  print(f\"\\nSimulating {num_simulations_n} Markov chains with {num_op_states+1} states:\")\n",
    "  # You can print or further analyze the simulated_chains\n",
    "  # for i, chain in enumerate(simulated_chains_n):\n",
    "  #   print(f\"Chain {i+1}: {chain[:20]}...\") # Print first 20 steps for brevity\n",
    "\n",
    "  # Optional: Calculate failure times for each simulation\n",
    "  failure_times_n = []\n",
    "  failed_state_index_n = num_op_states # The index of the failed state\n",
    "\n",
    "  for chain in simulated_chains_n:\n",
    "      # Find the first occurrence of the Failed state\n",
    "      try:\n",
    "          failure_step = chain.index(failed_state_index_n) * step_duration_n # Convert step index to time\n",
    "          failure_times_n.append(failure_step)\n",
    "      except ValueError:\n",
    "          # If the chain didn't fail within max_simulation_steps\n",
    "          # This simulation didn't reach the failed state\n",
    "          pass # Or append max_simulation_steps * step_duration_n\n",
    "\n",
    "  if failure_times_n:\n",
    "      average_simulated_mttf_n = np.mean(failure_times_n)\n",
    "      print(f\"\\nAverage simulated failure time across completed chains ({len(failure_times_n)} failures): {average_simulated_mttf_n:.2f}\")\n",
    "  else:\n",
    "      print(\"\\nNo failures observed in the simulations within the maximum steps.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KISS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
